<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">

  <title>DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link href='https://fonts.googleapis.com/css?family=Kalam' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=PT+Serif' rel='stylesheet'>
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <!-- <script defer src="static/js/fontawesome.all.min.js"></script> -->
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://kit.fontawesome.com/dcd6d05807.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/marked/9.1.0/marked.min.js"></script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
  <style>
    .title-container {
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .title.is-1.publication-title {
      margin: 0;
      position: relative;
      display: inline-block;
    }
    .title-wrapper {
      position: relative;
      display: inline-block;
    }
  </style>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="title-container">
              <h1 class="title is-2 publication-title">
                <span class="title-original">
                  <img src="static/images/icon.png" alt="DRIVEARENA Icon" style="vertical-align: middle; margin-right: 8px; width: 95px; height: auto;">
                  <span style="color: #ff7e5f;" >DriveArena: </span> A Closed-loop Generative Simulation<br> Platform for Autonomous Driving
                </span>
              </h1>
            </div>
            <br>
            <h2 class="subtitle has-text-centered">
              <span style="font-size: 35px; font-weight: bold; font-family: Kalam; color: #ff7e5f;">Evaluate Driving Agents on Worldwide Roads !<br> </span>
            </h2>
            <hr>

            <br>
            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=xGuZsikAAAAJ&hl=zh-CN" target="_blank">Xuemeng Yang</a><sup>1,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://wenlc.cn/" target="_blank">Licheng Wen</a><sup>1,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://april.zju.edu.cn/team/yukai-ma/" target="_blank">Yukai Ma</a><sup>2,1,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=OUtPkg0AAAAJ&hl=en" target="_blank">Jianbiao Mei</a><sup>2,1,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://sankin97.github.io/" target="_blank">Xin Li</a><sup>3,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/tiantian-wei-90328b262/" target="_blank">Tiantian Wei</a><sup>1,4,<i class="fa-solid fa-scale-balanced fa-xs"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://wenjie-2000.github.io/cv/" target="_blank">Wenjie Lei</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=vIU6eHYAAAAJ" target="_blank">Daocheng Fu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://pinlong-cai.github.io/" target="_blank">Pinlong Cai</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=w9fTWKQAAAAJ&hl=zh-CN" target="_blank">Min Dou</a><sup>1</sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=K0PpvLkAAAAJ" target="_blank">Botian Shi</a><sup>1,<i class="fa-regular fa-envelope fa-shake"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://faculty.ecnu.edu.cn/_s16/hl2/main.psp" target="_blank">Liang He</a><sup>5</sup>,
              </span>
              <span class="author-block">
                <a href="https://april.zju.edu.cn/team/dr-yong-liu/" target="_blank">Yong Liu</a><sup>2,<i class="fa-regular fa-envelope fa-shake"></i></sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ" target="_blank">Yu Qiao</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <br> 
              <span class="author-block"><sup>1</sup>Shanghai Artificial Intelligence Laboratory</span>&ensp;
              <span class="author-block"><sup>2</sup>Zhejiang University</span>&ensp;
              <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University</span>&ensp;
              <br>
              <span class="author-block"><sup>4</sup>Technical University of Munich</span>&ensp;
              <span class="author-block"><sup>5</sup>East China Normal University</span>&ensp;
              <span class="eql-cntrb"><br><sup><i class="fa-solid fa-scale-balanced fa-xs fa-shake"></i></sup>Equal contribution, <sup>&ensp;
                <i class="fa-regular fa-envelope fa-shake"></i></sup>Corresponding author</span>
              <!-- <span class="eql-cntrb"><small></small></span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <!-- <span class="link-block">
                  <a href=" " target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2408.00415" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://github.com/PJLab-ADG/DriveArena" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
        <h2 class="subtitle has-text-centered" style="color:#ff9161;">
          For optimal experience, we recommend using Chrome on PC.<br> Videos and images are clickable for enlarged viewing.
          Large videos may load slowly.
        </h2>
      </div>
    </div>
    
    <div class="video-container">
      <video autoplay muted loop>
        <source src="static/videos/singapore.mp4" type="video/mp4">
      </video>
      <span class="video-caption">SINGAPORE ONE-NORTH<br> 106 FRAME <br> 2Hz</span>
    </div>
    <div class="video-container">
      <video autoplay muted loop>
        <source src="static/videos/boston.mp4" type="video/mp4">
      </video>
      <span class="video-caption">BOSTON SEAPORT <br> 118 FRAME <br> 2Hz</span>
    </div>
    <div class="video-container">
      <video autoplay muted loop>
        <source src="static/videos/boston_thomas_park.mp4" type="video/mp4">
      </video>
      <span class="video-caption">BOSTON THOMAS PARK <br> 200 FRAME <br> 2Hz</span>
    </div>
    <div class="video-container">
      <video autoplay muted loop>
        <source src="static/videos/carla.mp4" type="video/mp4">
      </video>
      <span class="video-caption">CARLA TOWN05 <br> 26 FRAME <br> 2Hz</span>
    </div>

    <h2 class="subtitle has-text-centered">
      Closed-loop simulations with UniAD in generated environments.<br>
    </h2>

    <center>
      <embed type="image/png" src="static/images/maps.png" width="60%" />
    </center>
    <h2 class="subtitle has-text-centered">
      <br>
      <span style="font-size: 30px; font-weight: bold;font-family: kalam;">..... And support any worldwide street maps !<br> </span>
      <br>
    
    </h2>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              <b>
                <span style="font-size: 20px; line-height: 1.4; font-family: google sans">
                  This paper presents DriveArena, the first high-fidelity closed-loop simulation system 
                  designed for driving agents navigating in real scenarios. DriveArena
                  features a flexible, modular architecture, allowing for the
                  seamless interchange of its core components: Traffic Manager, 
                  a traffic simulator capable of generating realistic traffic flow on 
                  any worldwide street map, and World Dreamer, a
                  high-fidelity conditional generative model with infinite autoregression. 
                  This powerful synergy empowers any driving
                  agent capable of processing real-world images to navigate
                  in DriveArena simulated environment. The agent perceives 
                  its surroundings through images generated by World
                  Dreamer and output trajectories; then these trajectories
                  are fed into Traffic Manager, achieving realistic interactions
                   with other vehicles and producing a new scene layout. 
                  Finally, the latest scene layout is relayed back into
                  World Dreamer, perpetuating the simulation cycle. This
                  iterative process fosters closed-loop exploration within a
                  highly realistic environment, providing a valuable platform
                  for developing and evaluating driving agents across diverse
                  and challenging scenarios. 
                  DriveArena signifies a substantial leap forward
                  in leveraging generative image data
                  for the driving simulation platform, opening insights for
                  closed-loop autonomous driving.
                </span>
              </b>
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- End paper abstract -->



  <section class="section" id="Architecture">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title">DriveArena Architecture</h2>
          <div class="hero-body">
            <!-- <center>
              <embed type="image/png" src="static/images/pipeline_2.png" width="85%" />
            </center> -->
            <div style="text-align: center;">
              <img src="static/images/pipeline_2.png" alt="Pipeline Image" width="85%" class="fullscreenImage" style="cursor: pointer;">
            </div>
            <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
              The framework of our proposed DriveArena consists of two key components: 
              a <b>Traffic Manager</b> functioning as the backend physical engine and 
              a <b>World Dreamer</b> serving as the real-world image renderer. 
              Unlike conventional approaches, our DriveArena does not rely on pre-built digital
              assets or reconstructed 3D road models. Instead, the <b>Traffic Manager</b> adapts to road 
              networks of any city in OpenStreetMap (OSM) format, which can be directly downloaded from the 
              internet. This flexibility enables closed-loop traffic simulations on diverse urban layouts.
              <p></p>
              The<b> Traffic Manager</b> in DriveArena receives ego trajectories output by
              the autonomous driving agent and manages the movement of all background vehicles. It
              utilizes explicit traffic flow generation algorithms and enables the generation of a wider range of uncommon
              and potentially unsafe traffic scenarios, while also facilitating real-time collision detection between vehicles.
              <p></p>
              The<b> World Dreamer</b> in DriveArena generates realistic camera images that
              precisely correspond to the Traffic Manager's output. It
              also allows for user-defined prompts to control various elements of the generated images, such as street view style,
              time of day, and weather conditions, enhancing the diversity
              of the generated scenes. Specifically, it employs a diffusion-based
              model that utilizes the current map and vehicle layouts as control 
              conditions to produce surround-view images with cross-view and temporal consistency. 
            </h2>
            
            <!-- <center>
              <embed type="image/png" src="static/images/maps.png" width="100%" />
            </center> -->
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section hero is-small is-light">
    <!-- <div class="hero-body"> -->
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title">Generation Results based on nuScenes Data</h2>
            <div class="hero-body">
              <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
                The videos below present generation results using different text prompts on the same road network. 
                The layout conditions are projected onto the surrounding images. 
                The four sets of videos and text prompts exhibit significant differences in weather
                and lighting and can maintain their own styles during the continuous iteration process. 
                Each image illustrates that the road structure and vehicles strictly adhere to the given 
                control conditions while maintaining excellent consistency in the surrounding view.
              </h2>
            </div>
            </div>
          </div>
        </div>
      </div>
      <div class="video-container">
        <!-- <video autoplay muted loop> -->
        <video class="sync-video" muted loop>
          <source src="static/videos/sunny.mp4" type="video/mp4">
        </video>
        <span class="video-caption">"daytime, sunny, downtown, red buildings, cars......"</span>
      </div>
      <div class="video-container">
        <!-- <video autoplay muted loop> -->
        <video class="sync-video" muted loop>
          <source src="static/videos/rainy.mp4" type="video/mp4">
        </video>
        <span class="video-caption">"daytime, rainy, suburban, low buildings, wet surface......“</span>
      </div>
      <div class="video-container">
        <!-- <video autoplay muted loop> -->
        <video class="sync-video" muted loop>
          <source src="static/videos/cloudy.mp4" type="video/mp4">
        </video>
        <span class="video-caption">"daytime, cloudy, nature, green trees....."</span>
      </div>
      <div class="video-container">
        <!-- <video autoplay muted loop> -->
        <video class="sync-video" muted loop>
          <source src="static/videos/night.mp4" type="video/mp4">
        </video>
        <span class="video-caption">"night, clear, suburban, streetlights......"</span>
      </div>
  </section>
  

  <!-- Image carousel -->
  <section class="section hero is-small">
    <!-- <div class="hero-body"> -->
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title">Generation Results Using Different Road Networks as Input</h2>
            <!-- </div> -->
            <div class="hero-body">

              <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
                We randomly select one frame of images from the nuScenes dataset as reference images, 
                and choose three scenes from OSM and Carla. The inference are performed on them with DriveArena respectively. 
                As demonstrated below, the generated vehicles and road networks conform closely to control conditions, demonstrating strong 
                control capabilities. The style and weather of the generated pictures can also be consistent with the reference images.
              </h2>
              <div style="text-align: center;">
                <img src="static/images/ref-images.png" alt="MY ALT TEXT" width="70%" class="fullscreenImage" style="cursor: pointer;">
              </div>
              <!-- <center>
                <img src="static/images/ref-images.png" alt="MY ALT TEXT" width="70%" />
              </center> -->
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <!-- Your image here -->
                  <div style="text-align: center;">
                    <img src="static/images/scene1.png" alt="MY ALT TEXT" width="95%" class="fullscreenImage" style="cursor: pointer;">
                  </div>
                  <!-- <center>
                    <img src="static/images/scene1.png" alt="MY ALT TEXT" width="95%" />
                  </center> -->
                  <h2 class="subtitle has-text-centered">
                    A generated scene based on a randomly selected OSM roadmap.
                  </h2>
                </div>
                <div class="item">
                  <!-- Your image here -->
                  <div style="text-align: center;">
                    <img src="static/images/scene2.png" alt="MY ALT TEXT" width="95%" class="fullscreenImage" style="cursor: pointer;">
                  </div>
                  <!-- <center>
                    <img src="static/images/scene2.png" alt="MY ALT TEXT" width="95%" />
                  </center> -->
                  <h2 class="subtitle has-text-centered">
                    A generated scene based on a randomly selected OSM roadmap.
                  </h2>
                </div>
                <div class="item">
                  <!-- Your image here -->
                  <div style="text-align: center;">
                    <img src="static/images/scene3.png" alt="MY ALT TEXT" width="95%" class="fullscreenImage" style="cursor: pointer;">
                  </div>
                  <!-- <center>
                    <img src="static/images/scene3.png" alt="MY ALT TEXT" width="95%" />
                  </center> -->
                  <h2 class="subtitle has-text-centered">
                    A generated scene based on a randomly selected CARLA roadmap.
                  </h2>
                </div>
              </div>              
            </div>
          </div>
        </div>
      </div>
    <!-- </div> -->
  </section>
  <!-- End image carousel -->

  <!-- Image carousel -->
  <section class="section hero is-small is-light">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title">Generation Results Based on nuPlan Roadmaps</h2>
            <div class="hero-body">
              <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
                We also performed the inference directly on nuPlan dataset with World Dreamer to validate the scalability. 
                World Dreamer is fully trained on nuScenes dataset. The nuPlan data, on the other hand, originates from cities different from nuScenes 
                and features varying camera numbers and parameters.
                We select 6 cameras with a similar layout to the nuScenes dataset, and nuPlan's camera parameters are employed 
                to project object boxes and lane lines onto corresponding images as control conditions. As shown below, World Dreamer adheres 
                well to these conditions and generated coherent images when deployed in new cities and even with novel camera configurations.
              </h2>
            </div>
          </div>
        </div>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <div style="text-align: center;">
              <img src="static/images/nuplan_boston.png" alt="MY ALT TEXT" width="105%" class="fullscreenImage" style="cursor: pointer;">
            </div>
            <!-- <center>
              <img src="static/images/nuplan_boston.png" alt="MY ALT TEXT" width="105%" />
            </center> -->
          </div>
          <div class="item">
            <div style="text-align: center;">
              <img src="static/images/nuplan_pittsburgh.png" alt="MY ALT TEXT" width="105%" class="fullscreenImage" style="cursor: pointer;">
            </div>
            <!-- <center>
              <img src="static/images/nuplan_pittsburgh.png" alt="MY ALT TEXT" width="105%" />
            </center> -->
          </div>
          <div class="item">
            <div style="text-align: center;">
              <img src="static/images/nuplan_lasvegas.png" alt="MY ALT TEXT" width="105%" class="fullscreenImage" style="cursor: pointer;">
            </div>
            <!-- <center>
              <img src="static/images/nuplan_lasvegas.png" alt="MY ALT TEXT" width="105%" />
            </center> -->
          </div>

        </div>
        <h2 class="subtitle has-text-centered">
          Zero-shot inference on nuPlan data.
        </h2>
      </div>
  </section>
  <!-- End image carousel -->


  <!-- Image carousel -->
  <section class="section hero is-small">
    <!-- <div class="hero-body"> -->
      <div class="container">

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title">Comparison with MagicDrive on CARLA Road Networks</h2>
            <div class="hero-body">
              <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
                We used both MagicDrive and our World Dreamer
                to generate realistic images on the same Carla road network, which road style 
                differs significantly from that of nuScenes. 
                Consequently, the performance of MagicDrive, is slightly inferior in
                these conditions. As indicated by the yellow arrow, MagicDrive
                struggles with generating curved roads and fitting
                wide roads accurately. DriveArena, however, can produce 
                reasonable pictures that follow the road structure.
              </h2>
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <div style="text-align: center;">
                    <img src="static/images/magicdrive_comp1.png" alt="MY ALT TEXT" width="85%" class="fullscreenImage" style="cursor: pointer;">
                  </div>
                </div>
                <div class="item">
                  <div style="text-align: center;">
                    <img src="static/images/magicdrive_comp2.png" alt="MY ALT TEXT" width="85%" class="fullscreenImage" style="cursor: pointer;">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    <!-- </div> -->
  </section>
  <!-- End image carousel -->

   <!-- Image carousel -->
  <section class="section hero is-small is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title">Closed-Loop Driving in Simulation</h2>
          <div class="hero-body">
            <h2 class="subtitle has-text-justified" style="padding-top: 1rem;">
              Vision-based autonomous driving approaches, such as <a href="https://github.com/OpenDriveLab/UniAD" style="color: rgb(32, 100, 210);">UniAD</a>, 
              <a href="https://github.com/westlake-autolab/FusionAD" style="color: rgb(32, 100, 210);">FusionAD</a> and <a href="https://github.com/PJLab-ADG/DriveLikeAHuman" style="color: rgb(32, 100, 210);">Drive Like A Human</a>, 
              are typically trained 
              and evaluated on open-loop datasets. However, these algorithms lack the capability 
              to generalize directly to simulators for closed-loop evaluation, which hinders the demonstration of their true 
              performance potential. Therefore, we deploy UniAD with DriveArena to examine its true driving ability in closed-loop simulation.
            </h2>
          </div>
        </div>
      </div>
      <div class="video-container">
        <video autoplay muted loop>
          <source src="static/videos/uniad_closed_loop.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Performance of UniAD in a closed-loop simulation with DriveArena.
        </h2>
      </div>
      <div class="carousel results-carousel">
        <div class="item">
          <div style="text-align: center;">
            <img src="static/images/failure_case1.png" alt="MY ALT TEXT" width="70%" class="fullscreenImage" style="cursor: pointer;">
          </div>
          <!-- <center>
            <img src="static/images/failure_case1.png" alt="MY ALT TEXT" width="70%" />
          </center> -->
        </div>
        <div class="item">
          <!-- Your image here -->
          <div style="text-align: center;">
            <img src="static/images/failure_case2.png" alt="MY ALT TEXT" width="70%" class="fullscreenImage" style="cursor: pointer;">
          </div>
          <!-- <center>
            <img src="static/images/failure_case2.png" alt="MY ALT TEXT" width="70%" />
          </center> -->
        </div>
        <div class="item">
          <div style="text-align: center;">
            <img src="static/images/failure_case3.png" alt="MY ALT TEXT" width="70%" class="fullscreenImage" style="cursor: pointer;">
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Corner cases generated through planning failures of UniAD in the closed-loop simulation.
      </h2>
    </div>
  </section>

  <section class="section hero is-small">
    <!-- <div class="hero-body"> -->
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <!-- <h2 class="title">COMING SOON</h2> -->
            <h2 class="title">
              Long Multi-View Video Generation (DreamForge)
            </h2>
            
            <!-- </div> -->
            <div class="publication-links">
              <!-- Project Page link -->
              <span class="link-block">
                <a href="dreamforge/index.html" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Project Page</span>
                </a>
              </span>

              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href=" " target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv Paper</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <!-- <span class="link-block">
                <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

              <!-- ArXiv abstract Link -->
              <!-- <span class="link-block">
                <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span> -->
              <br>
              <br>
              <!-- <div class="hero-body">
                <h2 class="subtitle has-text-centered">
                  <b>COMING SOON...</b>
                </h2>
              </div> -->
            </div>
          </div>
        </div>
      </div>
      <div class="video-container">
        <video autoplay muted loop>
          <source src="dreamforge/static/videos/demo0.mp4" type="video/mp4">
        </video>
        <!-- <span class="video-caption">"night, clear, suburban, streetlights......"</span> -->
      </div>
      <div class="video-container">
        <video autoplay muted loop>
          <source src="dreamforge/static/videos/demo1.mp4" type="video/mp4">
        </video>
        <!-- <span class="video-caption">"daytime, cloudy, nature, green trees....."</span> -->
      </div>
      
  </section>

  <!-- Videos should be placed here. -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <div style="position: relative; font-size: 22px;">
        <button id="copyButton" style="position: absolute; top: 0; right: 0;">Copy</button>
        <pre><code id="bibtexCode">@article{yang2024drivearena,
  title={DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving}, 
  author={Xuemeng Yang and Licheng Wen and Yukai Ma and Jianbiao Mei and Xin Li and Tiantian Wei and Wenjie Lei and Daocheng Fu and Pinlong Cai and Min Dou and Botian Shi and Liang He and Yong Liu and Yu Qiao},
  journal={arXiv preprint arXiv:2408.00415},
  year={2024}
}
      </code></pre>
      </div>
    </div>
  </section>

  <script>
    document.addEventListener('fullscreenchange', function() {
      var fullscreenElement = document.fullscreenElement;
      if (fullscreenElement && fullscreenElement.classList.contains('fullscreenImage')) {
        fullscreenElement.classList.add('fullscreen-bg'); // Apply the background class to any fullscreen image
      } else {
        document.querySelectorAll('.fullscreen-bg').forEach(element => {
          element.classList.remove('fullscreen-bg'); // Remove the class when exiting fullscreen
        });
      }
    });
    
    document.querySelectorAll('.fullscreenImage').forEach(img => {
      img.addEventListener('click', function() {
        if (document.fullscreenElement) {
          document.exitFullscreen(); // Exit fullscreen mode
        } else if (this.requestFullscreen) {
          this.requestFullscreen(); // Enter fullscreen mode
        } else {
          alert('Fullscreen API is not supported by your browser.');
        }
      });
    });
  </script>

  <script>
    var copyButton = document.getElementById("copyButton");

    copyButton.addEventListener("click", function () {
      var codeElement = document.getElementById("bibtexCode");
      var textToCopy = codeElement.textContent;

      var textarea = document.createElement("textarea");
      textarea.value = textToCopy;
      document.body.appendChild(textarea);
      textarea.select();
      document.execCommand("copy");
      document.body.removeChild(textarea);

      copyButton.textContent = "✓ Copied!";

      setTimeout(function () {
        copyButton.textContent = "Copy";
      }, 2000); // Reset the button text after 2 seconds (adjust as needed)
    });
  </script>
  <script>
    document.querySelectorAll('.video-container').forEach(container => {
      container.addEventListener('click', function() {
        let video = this.querySelector('video'); // Find the video within the same container
        if (document.fullscreenElement) {
          document.exitFullscreen();
        } else if (video.requestFullscreen) {
          video.requestFullscreen(); // Request fullscreen on the video, not the caption
        }
      });
    });
  </script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
        var syncVideos = document.querySelectorAll('.sync-video'); // Select only videos with the 'sync-video' class
        var loaded = 0;

        syncVideos.forEach(function(video) {
            video.addEventListener('canplay', function() {
                loaded++;
                if (loaded === syncVideos.length) {
                    syncVideos.forEach(function(v) {
                        v.play(); // Play only the synchronized videos
                    });
                }
            });
        });
    });
</script>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center;">
              <i class="fa-solid fa-heart fa-beat-fade" style="color: #ff8787;"></i>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> <i class="fa-solid fa-heart fa-beat-fade" style="color: #ff8787;"></i>
              
                <a  href='https://www.free-counters.org/'>free HitCounter</a> <script type='text/javascript' src='https://www.freevisitorcounters.com/auth.php?id=b0f4a5a3752a7d922402634deadac2509e729c16'></script>
                <script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/1211530/t/5"></script>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>
